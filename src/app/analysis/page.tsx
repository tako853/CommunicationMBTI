'use client';

import { useState, useCallback, useRef } from 'react';
import { useRouter } from 'next/navigation';
import { WebcamCapture } from '@/components/WebcamCapture';
import { ScoreDisplay } from '@/components/ScoreDisplay';
import { ConversationLog } from '@/components/ConversationLog';
import { useFaceAnalysis } from '@/hooks/useFaceAnalysis';
import { useMediaPipe } from '@/hooks/useMediaPipe';
import { useAudioRecorder } from '@/hooks/useAudioRecorder';
import { useConversation } from '@/hooks/useConversation';
import { useTextToSpeech } from '@/hooks/useTextToSpeech';
import { calculateAllScores } from '@/services/scoreEngine';
import { analyzeSpeech } from '@/services/speechAnalysisService';
import { determineType } from '@/data/communicationTypes';
import type { TimelineEntry, CommunicationScores, CommunicationAxisScores } from '@/types/analysis';

type ConversationState = 'idle' | 'ai_speaking' | 'user_speaking' | 'processing';

export default function AnalysisPage() {
  const router = useRouter();
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [conversationState, setConversationState] = useState<ConversationState>('idle');
  const [scores, setScores] = useState<CommunicationScores>({
    expressiveness: 0,
    gestureActivity: 0,
    posturalOpenness: 0,
  });

  const timelineRef = useRef<TimelineEntry[]>([]);
  const userSpeechRef = useRef<string>('');
  const conversationStateRef = useRef<ConversationState>('idle');

  const faceAnalysis = useFaceAnalysis();
  const mediaPipe = useMediaPipe();
  const conversation = useConversation();
  const tts = useTextToSpeech();

  // æ²ˆé»™æ¤œå‡ºæ™‚ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’refã§ä¿æŒï¼ˆå¾ªç’°å‚ç…§å›é¿ï¼‰
  const handleSendMessageRef = useRef<() => void>(() => {});

  // æ²ˆé»™æ¤œå‡ºæ™‚ã«è‡ªå‹•é€ä¿¡
  const handleSilenceDetected = useCallback(() => {
    // user_speakingçŠ¶æ…‹ã®æ™‚ã®ã¿è‡ªå‹•é€ä¿¡
    if (conversationStateRef.current === 'user_speaking') {
      handleSendMessageRef.current();
    }
  }, []);

  const recorder = useAudioRecorder({
    silenceTimeout: 2000, // 2ç§’ã®æ²ˆé»™ã§é€ä¿¡
    onSilenceDetected: handleSilenceDetected,
  });

  const isLoading = faceAnalysis.isLoading || mediaPipe.isLoading;
  const isReady = faceAnalysis.isReady && mediaPipe.isReady;
  const error = faceAnalysis.error || mediaPipe.error || recorder.error || conversation.error || tts.error;

  const handleFrame = useCallback(
    async (video: HTMLVideoElement) => {
      await Promise.all([
        faceAnalysis.analyze(video),
        mediaPipe.analyze(video),
      ]);

      const entry: TimelineEntry = {
        timestamp: Date.now(),
        expressions: faceAnalysis.currentExpressions,
        pose: mediaPipe.currentPose,
        gesture: mediaPipe.currentGesture,
        headPose: mediaPipe.currentHeadPose,
        gaze: mediaPipe.currentGaze,
        handShape: mediaPipe.currentHandShape,
        bodyMovement: mediaPipe.currentBodyMovement,
      };

      timelineRef.current.push(entry);

      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ã‚³ã‚¢æ›´æ–°ï¼ˆæœ€æ–°30ã‚¨ãƒ³ãƒˆãƒªã§è¨ˆç®—ï¼‰
      const recentEntries = timelineRef.current.slice(-30);
      const newScores = calculateAllScores(recentEntries);
      setScores(newScores);
    },
    [faceAnalysis, mediaPipe]
  );

  // conversationStateã‚’æ›´æ–°ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
  const updateConversationState = useCallback((state: ConversationState) => {
    setConversationState(state);
    conversationStateRef.current = state;
  }, []);

  // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—çµ‚ã‚ã£ãŸã‚‰é€ä¿¡
  const handleSendMessage = useCallback(async () => {
    updateConversationState('processing');

    try {
      // éŒ²éŸ³åœæ­¢â†’Whisperã§æ–‡å­—èµ·ã“ã—
      const userMessage = await recorder.stopAndTranscribe();

      if (!userMessage || userMessage.trim().length === 0) {
        // ç™ºè¨€ãŒãªã‘ã‚Œã°å†åº¦éŒ²éŸ³é–‹å§‹
        updateConversationState('user_speaking');
        await recorder.startRecording();
        return;
      }

      userSpeechRef.current += userMessage + '\n';

      // AIã®è¿”ç­”ã‚’å–å¾—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¯ã¾ã è¡¨ç¤ºã—ãªã„ï¼‰
      const aiText = await conversation.sendMessage(userMessage, true);
      updateConversationState('ai_speaking');

      // éŸ³å£°ã‚’å†ç”Ÿ
      await tts.speak(aiText);

      // éŸ³å£°å†ç”Ÿå¾Œã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
      conversation.addPendingMessage();

      // å†ã³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¿ãƒ¼ãƒ³ï¼šéŒ²éŸ³é–‹å§‹
      updateConversationState('user_speaking');
      await recorder.startRecording();
    } catch (e) {
      console.error('Failed to send message:', e);
      updateConversationState('user_speaking');
      await recorder.startRecording();
    }
  }, [updateConversationState, recorder, conversation, tts]);

  // handleSendMessageã‚’refã«ç™»éŒ²
  handleSendMessageRef.current = handleSendMessage;

  // ä¼šè©±ã‚’é–‹å§‹
  const handleStartConversation = async () => {
    timelineRef.current = [];
    userSpeechRef.current = '';
    setIsAnalyzing(true);
    updateConversationState('ai_speaking');

    try {
      // AIãŒæœ€åˆã«è©±ã—ã‹ã‘ã‚‹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¯ã¾ã è¡¨ç¤ºã—ãªã„ï¼‰
      const aiMessage = await conversation.startConversation(true);

      // éŸ³å£°ã‚’å†ç”Ÿ
      await tts.speak(aiMessage);

      // éŸ³å£°å†ç”Ÿå¾Œã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
      conversation.addPendingMessage();

      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¿ãƒ¼ãƒ³ï¼šéŒ²éŸ³é–‹å§‹
      updateConversationState('user_speaking');
      await recorder.startRecording();
    } catch (e) {
      console.error('Failed to start conversation:', e);
      updateConversationState('idle');
      setIsAnalyzing(false);
    }
  };

  // ä¼šè©±ã‚’çµ‚äº†
  const handleEndConversation = async () => {
    await recorder.stopRecording();
    tts.stop();
    setIsAnalyzing(false);
    updateConversationState('idle');
  };

  // çµæœã‚’åˆ†æ
  const handleAnalyze = async () => {
    setIsProcessing(true);

    try {
      // è»¸3ï¼ˆéè¨€èªã‚’ä¼ãˆã‚‹åŠ›ï¼‰ã¯æ˜ åƒã‹ã‚‰è¨ˆç®—
      const finalScores = calculateAllScores(timelineRef.current);
      const nonverbalExpression = Math.round(
        (finalScores.expressiveness + finalScores.gestureActivity + finalScores.posturalOpenness) / 3
      );

      // è»¸1, 2, 4ã¯éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰GPTã§åˆ†æ
      let speechScores = {
        assertiveness: 50,
        listening: 50,
        nonverbalReading: 50,
      };

      const userTranscript = conversation.getUserTranscript();
      const duration = conversation.getDuration();

      if (userTranscript.trim().length > 0) {
        try {
          speechScores = await analyzeSpeech(userTranscript, duration);
        } catch (e) {
          console.error('Speech analysis failed:', e);
        }
      }

      // å…¨è»¸ã®ã‚¹ã‚³ã‚¢ã‚’çµ±åˆ
      const axisScores: CommunicationAxisScores = {
        assertiveness: speechScores.assertiveness,
        listening: speechScores.listening,
        nonverbalExpression,
        nonverbalReading: speechScores.nonverbalReading,
      };

      // ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
      const type = determineType(axisScores);

      // çµæœãƒšãƒ¼ã‚¸ã«é·ç§»
      const params = new URLSearchParams({
        a: axisScores.assertiveness.toString(),
        l: axisScores.listening.toString(),
        n: axisScores.nonverbalExpression.toString(),
        r: axisScores.nonverbalReading.toString(),
      });

      router.push(`/result/${type}?${params.toString()}`);
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div className="min-h-screen p-4">
      <div className="flex justify-center mb-4">
        <img
          src="/types/logo.jpg"
          alt="ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³MBTI"
          style={{ height: '60px', width: 'auto' }}
        />
      </div>

      {isLoading && (
        <div className="text-center p-8">
          <div className="text-lg">ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...</div>
        </div>
      )}

      {error && (
        <div className="text-center p-4 bg-red-100 text-red-700 rounded mb-4">
          ã‚¨ãƒ©ãƒ¼: {error}
        </div>
      )}

      {isReady && (
        <div className="max-w-5xl mx-auto space-y-4">
          {/* ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: ä¼šè©±ãƒ­ã‚° + ã‚«ãƒ¡ãƒ©ï¼ˆå³æ¨ªï¼‰ */}
          <div className="flex gap-4">
            {/* ä¼šè©±ãƒ­ã‚°ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰ */}
            <div className="flex-1 bg-white rounded-lg shadow-sm border p-4">
              <div className="flex items-center justify-between mb-3">
                <h2 className="text-lg font-semibold">ä¼šè©±</h2>
                {/* çŠ¶æ…‹è¡¨ç¤º */}
                <div className="text-sm">
                  {(conversationState === 'ai_speaking' || tts.isSpeaking || conversation.isLoading) && (
                    <span className="text-orange-600 font-medium">
                      {conversation.isLoading ? 'ğŸ¤” è€ƒãˆä¸­...' : 'ğŸ”Š AIãŒè©±ã—ã¦ã„ã¾ã™...'}
                    </span>
                  )}
                  {conversationState === 'user_speaking' && !tts.isSpeaking && !conversation.isLoading && (
                    <span className="text-blue-600 font-medium">
                      ğŸ¤ {recorder.hasSpeechStarted ? 'è‡ªå‹•é€ä¿¡å¾…ã¡...' : 'ãŠè©±ã—ãã ã•ã„'}
                    </span>
                  )}
                  {conversationState === 'processing' && !conversation.isLoading && (
                    <span className="text-gray-600 font-medium">â³ æ–‡å­—èµ·ã“ã—ä¸­...</span>
                  )}
                </div>
              </div>
              <ConversationLog
                messages={conversation.messages}
                isLoading={conversation.isLoading}
                isSpeaking={tts.isSpeaking}
                isUserSpeaking={conversationState === 'user_speaking' && !tts.isSpeaking}
                isRecording={recorder.isRecording}
                hasSpeechStarted={recorder.hasSpeechStarted}
                isProcessing={conversationState === 'processing' && !conversation.isLoading}
              />
            </div>

            {/* ã‚«ãƒ¡ãƒ©ï¼ˆå³æ¨ªï¼‰ */}
            <div className="flex-shrink-0 w-48 md:w-56">
              <div className="rounded-lg overflow-hidden shadow-lg border-2 border-gray-200 relative">
                <WebcamCapture
                  onFrame={handleFrame}
                  isAnalyzing={isAnalyzing}
                />
                {/* éŒ²éŸ³ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */}
                {conversationState === 'user_speaking' && recorder.isRecording && (
                  <div className="absolute top-2 left-2 flex items-center gap-1 bg-black/50 px-2 py-1 rounded text-white text-xs">
                    <div className="w-2 h-2 rounded-full bg-red-500 animate-pulse" />
                    REC
                  </div>
                )}
              </div>
            </div>
          </div>

          {/* æ“ä½œãƒœã‚¿ãƒ³ */}
          <div className="flex gap-2 justify-center flex-wrap">
            {!isAnalyzing ? (
              <button
                onClick={handleStartConversation}
                disabled={isProcessing}
                className="bg-blue-600 text-white px-6 py-2 rounded-lg hover:bg-blue-700 disabled:bg-gray-400"
              >
                ä¼šè©±ã‚’é–‹å§‹
              </button>
            ) : (
              <>
                {conversationState === 'user_speaking' && (
                  <button
                    onClick={handleSendMessage}
                    className="bg-blue-600 text-white px-6 py-2 rounded-lg hover:bg-blue-700"
                  >
                    ç™ºè¨€ã‚’é€ä¿¡
                  </button>
                )}
                <button
                  onClick={handleEndConversation}
                  className="bg-gray-600 text-white px-6 py-2 rounded-lg hover:bg-gray-700"
                >
                  ä¼šè©±ã‚’çµ‚äº†
                </button>
              </>
            )}

            {conversation.messages.length > 0 && !isAnalyzing && (
              <button
                onClick={handleAnalyze}
                disabled={isProcessing}
                className="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 disabled:bg-gray-400"
              >
                {isProcessing ? 'åˆ†æä¸­...' : 'çµæœã‚’è¦‹ã‚‹'}
              </button>
            )}
          </div>

          {/* ã‚¹ã‚³ã‚¢è¡¨ç¤º */}
          <ScoreDisplay
            scores={scores}
            currentExpressions={faceAnalysis.currentExpressions}
            currentPose={mediaPipe.currentPose}
            currentGesture={mediaPipe.currentGesture}
            currentHeadPose={mediaPipe.currentHeadPose}
            currentGaze={mediaPipe.currentGaze}
            currentHandShape={mediaPipe.currentHandShape}
            currentBodyMovement={mediaPipe.currentBodyMovement}
          />
        </div>
      )}
    </div>
  );
}
